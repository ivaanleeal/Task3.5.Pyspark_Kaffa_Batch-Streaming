{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a54fc68d-ea6f-453b-b24c-7c973b6dc4a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql.functions import *\n",
    "from pyspark.sql.types import *\n",
    "\n",
    "# 1. ConfiguraciÃ³n de Spark (Misma estructura que tu archivo de pedidos)\n",
    "packages = [\n",
    "    \"org.apache.spark:spark-sql-kafka-0-10_2.12:3.5.0\",\n",
    "    \"org.apache.hadoop:hadoop-aws:3.3.4\",\n",
    "    \"com.amazonaws:aws-java-sdk-bundle:1.12.262\"\n",
    "]\n",
    "\n",
    "spark = SparkSession.builder \\\n",
    "    .appName(\"AlertasTemperaturaStreaming\") \\\n",
    "    .config(\"spark.jars.packages\", \",\".join(packages)) \\\n",
    "    .config(\"spark.hadoop.fs.s3a.endpoint\", \"http://minio:9000\") \\\n",
    "    .config(\"spark.hadoop.fs.s3a.access.key\", \"minioadmin\") \\\n",
    "    .config(\"spark.hadoop.fs.s3a.secret.key\", \"minioadmin\") \\\n",
    "    .config(\"spark.hadoop.fs.s3a.path.style.access\", \"true\") \\\n",
    "    .config(\"spark.hadoop.fs.s3a.impl\", \"org.apache.hadoop.fs.s3a.S3AFileSystem\") \\\n",
    "    .config(\"spark.hadoop.fs.s3a.connection.ssl.enabled\", \"false\") \\\n",
    "    .getOrCreate()\n",
    "\n",
    "spark.sparkContext.setLogLevel(\"WARN\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3ca87fd3-572b-4485-86be-8e23a8674e03",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… Monitor de Humedad (CSV) activo en segundo plano.\n",
      "Usa la celda de abajo para detenerlo cuando quieras.\n",
      "--- Batch 0: Esperando datos vÃ¡lidos... ---\n",
      "\n",
      "--- ðŸ’§ MONITOR DE HUMEDAD CSV (Batch: 1) ---\n",
      "Total de mensajes procesados: 1\n",
      "Promedio de humedad (Ãšltimas 10 del lote):\n",
      "+-------------------------+\n",
      "|Humedad_Promedio_Reciente|\n",
      "+-------------------------+\n",
      "|                    46.96|\n",
      "+-------------------------+\n",
      "\n",
      "Lecturas actuales por sensor:\n",
      "+---------+-------------+--------------+\n",
      "|sensor_id|Media_Humedad|Total_Lecturas|\n",
      "+---------+-------------+--------------+\n",
      "|    hum-1|        46.96|             1|\n",
      "+---------+-------------+--------------+\n",
      "\n",
      "\n",
      "--- ðŸ’§ MONITOR DE HUMEDAD CSV (Batch: 2) ---\n",
      "Total de mensajes procesados: 6\n",
      "Promedio de humedad (Ãšltimas 10 del lote):\n",
      "+-------------------------+\n",
      "|Humedad_Promedio_Reciente|\n",
      "+-------------------------+\n",
      "|       43.846000000000004|\n",
      "+-------------------------+\n",
      "\n",
      "Lecturas actuales por sensor:\n",
      "+---------+------------------+--------------+\n",
      "|sensor_id|     Media_Humedad|Total_Lecturas|\n",
      "+---------+------------------+--------------+\n",
      "|    hum-1|43.846000000000004|             5|\n",
      "+---------+------------------+--------------+\n",
      "\n",
      "\n",
      "--- ðŸ’§ MONITOR DE HUMEDAD CSV (Batch: 3) ---\n",
      "Total de mensajes procesados: 10\n",
      "Promedio de humedad (Ãšltimas 10 del lote):\n",
      "+-------------------------+\n",
      "|Humedad_Promedio_Reciente|\n",
      "+-------------------------+\n",
      "|       43.817499999999995|\n",
      "+-------------------------+\n",
      "\n",
      "Lecturas actuales por sensor:\n",
      "+---------+------------------+--------------+\n",
      "|sensor_id|     Media_Humedad|Total_Lecturas|\n",
      "+---------+------------------+--------------+\n",
      "|    hum-1|43.817499999999995|             4|\n",
      "+---------+------------------+--------------+\n",
      "\n",
      "\n",
      "--- ðŸ’§ MONITOR DE HUMEDAD CSV (Batch: 4) ---\n",
      "Total de mensajes procesados: 15\n",
      "Promedio de humedad (Ãšltimas 10 del lote):\n",
      "+-------------------------+\n",
      "|Humedad_Promedio_Reciente|\n",
      "+-------------------------+\n",
      "|       44.339999999999996|\n",
      "+-------------------------+\n",
      "\n",
      "Lecturas actuales por sensor:\n",
      "+---------+------------------+--------------+\n",
      "|sensor_id|     Media_Humedad|Total_Lecturas|\n",
      "+---------+------------------+--------------+\n",
      "|    hum-1|44.339999999999996|             5|\n",
      "+---------+------------------+--------------+\n",
      "\n",
      "\n",
      "--- ðŸ’§ MONITOR DE HUMEDAD CSV (Batch: 5) ---\n",
      "Total de mensajes procesados: 20\n",
      "Promedio de humedad (Ãšltimas 10 del lote):\n",
      "+-------------------------+\n",
      "|Humedad_Promedio_Reciente|\n",
      "+-------------------------+\n",
      "|                   44.088|\n",
      "+-------------------------+\n",
      "\n",
      "Lecturas actuales por sensor:\n",
      "+---------+-------------+--------------+\n",
      "|sensor_id|Media_Humedad|Total_Lecturas|\n",
      "+---------+-------------+--------------+\n",
      "|    hum-1|       44.088|             5|\n",
      "+---------+-------------+--------------+\n",
      "\n",
      "\n",
      "--- ðŸ’§ MONITOR DE HUMEDAD CSV (Batch: 6) ---\n",
      "Total de mensajes procesados: 24\n",
      "Promedio de humedad (Ãšltimas 10 del lote):\n",
      "+-------------------------+\n",
      "|Humedad_Promedio_Reciente|\n",
      "+-------------------------+\n",
      "|                   44.385|\n",
      "+-------------------------+\n",
      "\n",
      "Lecturas actuales por sensor:\n",
      "+---------+-------------+--------------+\n",
      "|sensor_id|Media_Humedad|Total_Lecturas|\n",
      "+---------+-------------+--------------+\n",
      "|    hum-1|       44.385|             4|\n",
      "+---------+-------------+--------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql.functions import col, split, to_timestamp, avg, count\n",
    "\n",
    "# 1. Lectura de Kafka (Se mantiene igual)\n",
    "kafka_hum_df = spark.readStream \\\n",
    "    .format(\"kafka\") \\\n",
    "    .option(\"kafka.bootstrap.servers\", \"kafka:29092\") \\\n",
    "    .option(\"subscribe\", \"humidity-sensors\") \\\n",
    "    .option(\"startingOffsets\", \"latest\") \\\n",
    "    .load()\n",
    "\n",
    "# 2. Parseo para formato CSV (separado por comas)\n",
    "# Dividimos el valor por comas y asignamos cada posiciÃ³n a su columna\n",
    "parsed_hum_df = kafka_hum_df.selectExpr(\"CAST(value AS STRING) as raw_data\") \\\n",
    "    .select(split(col(\"raw_data\"), \",\").alias(\"fields\")) \\\n",
    "    .select(\n",
    "        col(\"fields\").getItem(0).alias(\"sensor_id\"),\n",
    "        col(\"fields\").getItem(1).cast(\"double\").alias(\"humidity\"),\n",
    "        col(\"fields\").getItem(2).alias(\"original_timestamp\"),\n",
    "        col(\"fields\").getItem(3).alias(\"location\")\n",
    "    ) \\\n",
    "    .withColumn(\"event_timestamp\", to_timestamp(col(\"original_timestamp\")))\n",
    "\n",
    "# Variables para el contador\n",
    "total_acumulado = 0\n",
    "\n",
    "# 3. FunciÃ³n de MonitorizaciÃ³n (Adaptada)\n",
    "def monitor_humedad(batch_df, batch_id):\n",
    "    global total_acumulado\n",
    "    \n",
    "    # Limpiamos filas vacÃ­as\n",
    "    clean_df = batch_df.filter(col(\"sensor_id\").isNotNull())\n",
    "    \n",
    "    if not clean_df.isEmpty():\n",
    "        conteo_lote = clean_df.count()\n",
    "        total_acumulado += conteo_lote\n",
    "        \n",
    "        print(f\"\\n--- ðŸ’§ MONITOR DE HUMEDAD CSV (Batch: {batch_id}) ---\")\n",
    "        print(f\"Total de mensajes procesados: {total_acumulado}\")\n",
    "        \n",
    "        print(\"Promedio de humedad (Ãšltimas 10 del lote):\")\n",
    "        clean_df.orderBy(col(\"event_timestamp\").desc()) \\\n",
    "                .limit(10) \\\n",
    "                .agg(avg(\"humidity\").alias(\"Humedad_Promedio_Reciente\")) \\\n",
    "                .show()\n",
    "        \n",
    "        print(\"Lecturas actuales por sensor:\")\n",
    "        clean_df.groupBy(\"sensor_id\").agg(\n",
    "            avg(\"humidity\").alias(\"Media_Humedad\"),\n",
    "            count(\"*\").alias(\"Total_Lecturas\")\n",
    "        ).show()\n",
    "    else:\n",
    "        print(f\"--- Batch {batch_id}: Esperando datos vÃ¡lidos... ---\")\n",
    "\n",
    "# 4. Inicio del Stream\n",
    "query_humedad = parsed_hum_df.writeStream \\\n",
    "    .foreachBatch(monitor_humedad) \\\n",
    "    .trigger(processingTime=\"5 seconds\") \\\n",
    "    .start()\n",
    "\n",
    "print(\"âœ… Monitor de Humedad (CSV) activo en segundo plano.\")\n",
    "print(\"Usa la celda de abajo para detenerlo cuando quieras.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "56563608-a99d-46e0-a3a4-10677fc6754c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Deteniendo query: None (ID: ca2c6363-c5cd-4d90-a5a1-f087be39b6f6)\n",
      "ðŸ›‘ Todos los procesos detenidos.\n"
     ]
    }
   ],
   "source": [
    "for query in spark.streams.active:\n",
    "    print(f\"Deteniendo query: {query.name} (ID: {query.id})\")\n",
    "    query.stop()\n",
    "\n",
    "print(\"ðŸ›‘ Todos los procesos detenidos.\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
